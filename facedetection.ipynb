{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ymaqlehHNf2jTJk3qB_96l2mZfLYInZL",
      "authorship_tag": "ABX9TyOdIV1f0pepUk3AFJsQeVCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charitythedatascientist/computer_vision/blob/main/facedetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "SdDehRtn2FWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0K6Z-nJLn6SA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing the images\n",
        "\n",
        "image_path = '/content/drive/MyDrive/photos'\n",
        "os.listdir(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOWSAE1yUSbJ",
        "outputId": "a4b65175-2a56-42fb-e775-5c5a4531f8b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['20240907_090503.heic',\n",
              " '20241005_162036.heic',\n",
              " '20240907_090450.heic',\n",
              " '20240907_090458.heic',\n",
              " '20241026_150404.heic',\n",
              " '20240907_090454.heic',\n",
              " '20231127_142517.jpg',\n",
              " '20231127_142509.jpg',\n",
              " '20231013_180020.jpg',\n",
              " '20230921_232218.jpg',\n",
              " '20231031_131626.jpg',\n",
              " '20231013_180022.jpg',\n",
              " '20231015_121109.jpg',\n",
              " '20231031_150110.jpg',\n",
              " '20231213_112812.png']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data** **Preprocessing**"
      ],
      "metadata": {
        "id": "jXgf3H4D13n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_faces(image_path):\n",
        "    # Create empty lists for X (features) and y (labels)\n",
        "    X, y = [], []\n",
        "\n",
        "    # os.listdir(image_path) provides a list of all files in the directory.\n",
        "    for idx, filename in enumerate(os.listdir(image_path)):\n",
        "        # For files that end with .jpg or .png\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            # Each image's path is derived\n",
        "            img_path = os.path.join(image_path, filename)\n",
        "\n",
        "            # OpenCV's imread() function is used to read the image and convert it into a numpy array.\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # The image is converted into grayscale before performing face detection for computational efficiency.\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Load the classifier and create an instance of the class.\n",
        "            # The Haarcascade_frontalface_default.xml is used since it is designed to detect frontal faces.\n",
        "            face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "            # Hyperparameter tuning:\n",
        "            # The detectMultiScale() method is used to identify faces of different sizes in the input image.\n",
        "            # The first parameter gray_img is created using the cv2.cvtColor() method.\n",
        "            # The scaleFactor parameter scales down the size of the input image to make it easier for the algorithm to detect larger faces.\n",
        "            # The cascade classifier applies a sliding window through the image to detect faces in it.\n",
        "            # The classifier initially captures a large number of false positives, which are eliminated using the minNeighbors parameter.\n",
        "            # The minNeighbors parameter specifies the number of rectangles that need to be identified for an object to be considered valid.\n",
        "            # The minSize parameter sets the min size of the object to be detected.\n",
        "            faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "            # Detect faces in the image\n",
        "            # Create a for loop to iterate through each detected face in the faces list.\n",
        "            # The faces variable contains a list of bounding boxes for each detected face in an image.\n",
        "            # x: the x-coordinate in the top-left corner of the face\n",
        "            # y_: the y-coordinate in the top-left corner of the face\n",
        "            # w: the width of the face\n",
        "            # h: the height of the face\n",
        "            for (x, y_, w, h) in faces:\n",
        "                face = gray_img[y_:y_+h, x:x+w]\n",
        "                resized_face = cv2.resize(face, (100, 100))  # Resize to a consistent size (100x100)\n",
        "                X.append(resized_face.flatten())  # Flatten the face for ML model input\n",
        "                y.append(1)  # Label all faces as \"1\" for matching\n",
        "\n",
        "    # Return the processed features and labels as numpy arrays\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "OYQrciJh0eer"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model** **Training**"
      ],
      "metadata": {
        "id": "5szk4cp_1zCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training():\n",
        "  X, y = preprocess_faces()\n",
        "  if len(X) == 0:\n",
        "    print(\"No images available\")\n",
        "  if len(y):\n",
        "    print(\"No labels provided\")\n",
        "\n",
        " #Creating an instance of the KNN model\n",
        "  knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
        "  #Fitting the model to the training dataset\n",
        "  knn_model.fit(X, y)\n",
        "\n",
        "  # Save the model using Python's pickle module\n",
        "  #This allows you to later load the model and make predictions without retraining it.\n",
        "  with open(knn_model, 'wb') as f:\n",
        "    #the file is opened for writing in binary mode\n",
        "    #pickle.dump serializes the model into a byte-stream and write it to a file.\n",
        "    pickle.dump(knn_model, f)\n",
        "\n",
        "  print(\"The model has been trained and saved as a pkl file.\")\n",
        "\n",
        "  return knn_model"
      ],
      "metadata": {
        "id": "M-Bhm1c20fZS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing():\n",
        "  with open('knn_model.pkl', 'rb') as f:\n",
        "    knn_model = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "UiUYRk0AA0DF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}